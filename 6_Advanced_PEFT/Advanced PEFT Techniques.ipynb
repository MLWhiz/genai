{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbc618-34a0-4ca8-8683-11e247229155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torch transformers datasets peft accelerate evaluate bitsandbytes pandas\n",
    "!pip install --upgrade torch\n",
    "!pip install evaluate\n",
    "!pip install peft\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa6a5fe-0f35-44f1-ac82-d31f55179856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, pipeline\n",
    "from evaluate import load\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dab5152-60f5-476d-84f1-9940daebfbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"hf_SECRET_TOKEN\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2231c11b-ad75-4914-b36c-810a367c04b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "DATASET_NAME = \"tatsu-lab/alpaca\"\n",
    "ADAPTER_PATH = \"./lora_adapter\"\n",
    "MERGED_MODEL_PATH = \"./merged_lora_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14109c70-73e2-420f-b4c9-3c25c14b373a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. Prepare Dataset and Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def format_prompt(sample):\n",
    "    instruction = sample.get('instruction', '')\n",
    "    input_text = sample.get('input', '')\n",
    "    response = sample.get('output', '')\n",
    "    \n",
    "    if input_text:\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n\"\n",
    "    else:\n",
    "        prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n\"\n",
    "        \n",
    "    full_text = prompt + response\n",
    "    return {\"prompt\": prompt, \"full_text\": full_text}\n",
    "\n",
    "# Load, format, and tokenize a small subset of the data\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train[:500]\")\n",
    "formatted_dataset = dataset.map(format_prompt)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(examples[\"full_text\"], truncation=True, max_length=256, padding=\"max_length\")\n",
    "    # Convert to tensors and set labels for causal language modeling\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = formatted_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['instruction', 'input', 'output', 'text', 'prompt', 'full_text'])\n",
    "\n",
    "# Create a separate validation set for perplexity calculation\n",
    "eval_dataset = load_dataset(DATASET_NAME, split=\"train[500:1000]\")\n",
    "eval_dataset = eval_dataset.map(format_prompt).map(tokenize_function, batched=True)\n",
    "eval_dataset = eval_dataset.remove_columns(['instruction', 'input', 'output', 'text', 'prompt', 'full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0ae34-16bd-4437-a2b2-d432f71d607a",
   "metadata": {},
   "source": [
    "## LORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe8ffdc-505a-4997-88cc-c4840f385528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading Model and Tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6073b7aac437461281aa28097ccf57a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Load Model and Tokenizer ---\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee42d3cc-bf9b-4c47-b00f-dc9e01231cad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Setting up LoRA\n"
     ]
    }
   ],
   "source": [
    "# --- Setup LoRA\n",
    "# Simply enable training mode\n",
    "base_model.train()\n",
    "\n",
    "# Enable gradient computation for input embeddings (important for LoRA)\n",
    "base_model.get_input_embeddings().weight.requires_grad_(True)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(base_model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "421d8b48-483c-4d73-bc95-dd8041085b46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n",
      "✓ Trainable: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n"
     ]
    }
   ],
   "source": [
    "# --- Setup LoRA - See Trainable Params\n",
    "\n",
    "# Check that LoRA parameters require gradients\n",
    "has_trainable = False\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"✓ Trainable: {name}\")\n",
    "        has_trainable = True\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2824230e-bbf1-4a0c-a0f2-12a3217eb18b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17140/1976365797.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_steps=10,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b69706-e681-4767-b2e2-23b36b50015a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Evaluating the Model\n",
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 6.36\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation of untrained model ---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e17a5e5-0e4e-4b28-b94b-554ab64ddced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.117900</td>\n",
       "      <td>1.150921</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.122700</td>\n",
       "      <td>1.136840</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900ff19c-58ed-47f8-a9eb-ae866c6d4d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Saving adapter to ./lora_adapter\n"
     ]
    }
   ],
   "source": [
    "# --- Save the Adapter ---\n",
    "print(f\"\\nSaving adapter to {ADAPTER_PATH}\")\n",
    "peft_model.save_pretrained(ADAPTER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03830ce0-28a8-46aa-9cf6-0b4542b2e13d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Evaluating the Model\n",
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 3.11\n"
     ]
    }
   ],
   "source": [
    "# ---Evaluation on Trained Model---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff2a49b-167a-4e5f-95f2-5ed2d476f46c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Qualitative Evaluation (Side-by-Side) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instruction</th>\n",
       "      <th>Input</th>\n",
       "      <th>Base Model Output</th>\n",
       "      <th>Fine-Tuned Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the three primary colors?</td>\n",
       "      <td></td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "      <td>The three primary colors are red, blue, and ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain the concept of quantum entanglement in...</td>\n",
       "      <td></td>\n",
       "      <td>Quantum entanglement is a phenomenon in which ...</td>\n",
       "      <td>Quantum entanglement is a phenomenon in which ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Instruction Input  \\\n",
       "0                 What are the three primary colors?         \n",
       "1  Explain the concept of quantum entanglement in...         \n",
       "\n",
       "                                   Base Model Output  \\\n",
       "0  The three primary colors are red, blue, and ye...   \n",
       "1  Quantum entanglement is a phenomenon in which ...   \n",
       "\n",
       "                                   Fine-Tuned Output  \n",
       "0  The three primary colors are red, blue, and ye...  \n",
       "1  Quantum entanglement is a phenomenon in which ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---Qualitative Evaluation: Side-by-Side Comparison---\n",
    "\n",
    "# Use a few challenging prompts for qualitative assessment\n",
    "eval_prompts = [\n",
    "    {\"instruction\": \"What are the three primary colors?\", \"input\": \"\"},\n",
    "    {\"instruction\": \"Explain the concept of quantum entanglement in simple terms.\", \"input\": \"\"}\n",
    "]\n",
    "\n",
    "base_generator = pipeline('text-generation', model=base_model, tokenizer=tokenizer)\n",
    "fine_tuned_generator = pipeline('text-generation', model=peft_model, tokenizer=tokenizer)\n",
    "\n",
    "results_list = []\n",
    "for sample in eval_prompts:\n",
    "    prompt_text = format_prompt(sample)[\"prompt\"]\n",
    "    base_output = base_generator(prompt_text, max_new_tokens=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    lora_output = fine_tuned_generator(prompt_text, max_new_tokens=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    results_list.append({\n",
    "        \"Instruction\": sample[\"instruction\"],\n",
    "        \"Input\": sample[\"input\"],\n",
    "        \"Base Model Output\": base_output[0]['generated_text'].replace(prompt_text, \"\").strip(),\n",
    "        \"Fine-Tuned Output\": lora_output[0]['generated_text'].replace(prompt_text, \"\").strip()\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d0dd17-e02c-4dcb-8dbf-6fb9025f9fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge complete! The model now behaves like a standard transformer model.\n"
     ]
    }
   ],
   "source": [
    "# --- Merging for Zero Latency ---\n",
    "# Note: Merging requires enough memory to hold the full model in FP16\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "print(\"✅ Merge complete! The model now behaves like a standard transformer model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac02a547-1458-4f96-b8a4-4410757f0fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving merged model to ./merged_lora_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./merged_lora_model/tokenizer_config.json',\n",
       " './merged_lora_model/special_tokens_map.json',\n",
       " './merged_lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Saving merged model to {MERGED_MODEL_PATH}\")\n",
    "merged_model.save_pretrained(MERGED_MODEL_PATH)\n",
    "tokenizer.save_pretrained(MERGED_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3be851-711b-427c-9fd2-20a01cff34c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b9713ad6ec4f3396fc6dd0dd72d00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_model = AutoModelForCausalLM.from_pretrained(\"./merged_lora_model\")\n",
    "merged_tokenizer = AutoTokenizer.from_pretrained(\"./merged_lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75c31b-a366-4f7a-afd3-a90439cf65b5",
   "metadata": {},
   "source": [
    "## QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3412ee17-8f9d-4d4d-88c2-4beaf9bf06e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QLoRATrainer:\n",
    "    def __init__(self, model_name, device_map=\"auto\"):\n",
    "        self.model_name = model_name\n",
    "        self.device_map = device_map\n",
    "\n",
    "    def setup_quantization_config(self):\n",
    "        return BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "\n",
    "    def setup_production_qlora(self, r=16, lora_alpha=32, lora_dropout=0.05):\n",
    "        bnb_config = self.setup_quantization_config()\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=self.device_map,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        lora_config = LoraConfig(\n",
    "            r=r, lora_alpha=lora_alpha,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "            lora_dropout=lora_dropout, bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "        model = get_peft_model(model, lora_config)\n",
    "        model.print_trainable_parameters()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb4f29a-ab15-4cd1-8553-2d61fdb48d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qLoRATrainer = QLoRATrainer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471b486d-b88c-4e30-a381-48eef811a768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d0a8d9330a46f8b1d4577c258ca1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\n"
     ]
    }
   ],
   "source": [
    "qlora_model = qLoRATrainer.setup_production_qlora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56514703-1597-402a-af20-322e49a2a4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2537/1851140848.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_steps=10,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=qlora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ab6094-d799-47ff-837c-ce332f377921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 08:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.132400</td>\n",
       "      <td>1.162442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.124300</td>\n",
       "      <td>1.138778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58edaef6-e5a0-493c-b817-0882608d6274",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 3.11\n"
     ]
    }
   ],
   "source": [
    "# ---Evaluation on Trained Model---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd8cf1-315c-4865-ab1b-c1c989e852bb",
   "metadata": {},
   "source": [
    "## DORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165eb953-c62e-4ca8-b386-b6520a17c5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "class DoRATrainer:\n",
    "    def __init__(self, model_name, device_map=\"auto\"):\n",
    "        self.model_name = model_name\n",
    "        self.device_map = device_map\n",
    "\n",
    "    def setup_dora(self, r=16, lora_alpha=32, lora_dropout=0.1):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name, device_map=self.device_map, torch_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        # DoRA is enabled by setting use_dora=True in LoraConfig\n",
    "        dora_config = LoraConfig(\n",
    "            r=r,\n",
    "            lora_alpha=lora_alpha,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "            lora_dropout=lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "            use_dora=True,  # This is the key difference!\n",
    "        )\n",
    "        \n",
    "        model = get_peft_model(model, dora_config)\n",
    "        model.print_trainable_parameters()\n",
    "        print(\"✅ DoRA setup complete! This adapter will learn both directional and magnitude changes.\")\n",
    "        return model\n",
    "\n",
    "    def setup_dora_with_quantization(self, r=16, lora_alpha=32):\n",
    "        \"\"\"Combine DoRA with 4-bit quantization for maximum efficiency\"\"\"\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "        \n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=self.device_map,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        model = prepare_model_for_kbit_training(model)\n",
    "        \n",
    "        dora_config = LoraConfig(\n",
    "            r=r, lora_alpha=lora_alpha,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "            lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\",\n",
    "            use_dora=True,  # Enable DoRA\n",
    "        )\n",
    "        \n",
    "        model = get_peft_model(model, dora_config)\n",
    "        model.print_trainable_parameters()\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae39349-2636-4e2a-9cbb-0a48aa59be53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doRATrainer = DoRATrainer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e329eb-c4b2-41ee-9f25-231c9b5b7cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c624796e9045328641b5dbdecc2cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,959,168 || all params: 7,255,691,264 || trainable%: 0.1924\n"
     ]
    }
   ],
   "source": [
    "dora_model = doRATrainer.setup_dora_with_quantization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ab5ffa-6c6b-4619-bf1d-dbe93939fdab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15310/1709527944.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_steps=10,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=dora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bcc02ad-73c9-4c00-af65-672b74de911f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 11:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.133200</td>\n",
       "      <td>1.164120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.127200</td>\n",
       "      <td>1.141404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23b22127-5b57-4133-b211-ca235e4cbd00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 01:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 3.12\n"
     ]
    }
   ],
   "source": [
    "# ---Evaluation on Trained Model---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0dfa8-2a4e-4cf2-bf7d-7e13f8797616",
   "metadata": {},
   "source": [
    "## Adalora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b8b3be-d0d1-4fb9-9abe-a284b86ca135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import AdaLoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a44f08-8297-4cc9-9283-82ba160324f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdaLoRATrainer:\n",
    "    def __init__(self, model_name, device_map=\"auto\"):\n",
    "        self.model_name = model_name\n",
    "        self.device_map = device_map\n",
    "\n",
    "    def setup_adalora(self, actual_training_steps, device_map=\"auto\"):\n",
    "        \"\"\"Setup AdaLoRA with proper total_step matching your training\"\"\"\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name, device_map=self.device_map, torch_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "        # Configure AdaLoRA for your actual training length\n",
    "        adalora_config = AdaLoraConfig(\n",
    "            peft_type=\"ADALORA\", \n",
    "            task_type=\"CAUSAL_LM\",\n",
    "            init_r=32,\n",
    "            lora_alpha=32, \n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "            orth_reg_weight=0.5,\n",
    "            total_step=actual_training_steps,\n",
    "            deltaT=max(5, actual_training_steps // 20),\n",
    "            beta1=0.85,\n",
    "            beta2=0.85,\n",
    "        )\n",
    "\n",
    "        print(f\"🔧 AdaLoRA Configuration:\")\n",
    "        print(f\"   total_step: {adalora_config.total_step}\")\n",
    "        print(f\"   deltaT: {adalora_config.deltaT}\")\n",
    "        print(f\"   Expected adaptations: {actual_training_steps // adalora_config.deltaT}\")\n",
    "\n",
    "        model = get_peft_model(model, adalora_config)\n",
    "        model.print_trainable_parameters()\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf67bcdf-6668-4345-b0f9-af09ed12bd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adaloRATrainer = AdaLoRATrainer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccdaddcd-6358-484b-94c7-1125da10e99a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1cb2c35cb2453da222935b8b81ea7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 AdaLoRA Configuration:\n",
      "   total_step: 125\n",
      "   deltaT: 6\n",
      "   Expected adaptations: 20\n",
      "trainable params: 27,267,072 || all params: 7,268,999,296 || trainable%: 0.3751\n"
     ]
    }
   ],
   "source": [
    "adalora_model = adaloRATrainer.setup_adalora(actual_training_steps=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfde2193-79f0-48a9-98ff-fa9a7a68bc56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4730/874768344.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_steps=10,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=adalora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17cf8ff-d683-4d8f-aa58-15c90c290487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.875600</td>\n",
       "      <td>2.064665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.671800</td>\n",
       "      <td>1.587517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2b3320-94ed-4892-85b8-9b5877e8a632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 4.60\n"
     ]
    }
   ],
   "source": [
    "# ---Evaluation on Trained Model---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724e9f8-c8f9-4565-ad38-69962c2cef4c",
   "metadata": {},
   "source": [
    "## IA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69fae7fd-ed32-4f58-80b2-f7b99685dc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import IA3Config\n",
    "\n",
    "class IA3Trainer:\n",
    "    def __init__(self, model_name, device_map=\"auto\"):\n",
    "        self.model_name = model_name\n",
    "        self.device_map = device_map\n",
    "\n",
    "    def setup_ia3(self):\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name, device_map=self.device_map, torch_dtype=torch.float16\n",
    "        )\n",
    "        # IA³ targets key/value projections and the feed-forward network\n",
    "        ia3_config = IA3Config(\n",
    "            peft_type=\"IA3\", task_type=\"CAUSAL_LM\",\n",
    "            target_modules=[\"k_proj\", \"v_proj\", \"down_proj\"],\n",
    "            feedforward_modules=[\"down_proj\"],\n",
    "        )\n",
    "        model = get_peft_model(model, ia3_config)\n",
    "        model.print_trainable_parameters()\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89f6c65-4b02-40a6-b8b5-bff9e431a6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ia3Trainer = IA3Trainer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fc5c8d-1e50-44b3-a9c7-7181a19e67bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad80ae2b22c40abaac9c653cf5e120e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 524,288 || all params: 7,242,256,384 || trainable%: 0.0072\n"
     ]
    }
   ],
   "source": [
    "ia3_model = ia3Trainer.setup_ia3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3ebd225-16b3-492c-968d-96909e78501b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18529/3204143515.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Setup ---\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    warmup_steps=10,\n",
    "    save_total_limit=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50\n",
    "\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=8,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=ia3_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1352482-dc6a-4724-99f0-26c4d54682f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.706900</td>\n",
       "      <td>1.751249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.598600</td>\n",
       "      <td>1.698713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Start Training ---\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "130439bd-de52-47b4-9784-bac0ee4bc412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantitative Evaluation (Perplexity) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on eval set: 5.43\n"
     ]
    }
   ],
   "source": [
    "# ---Evaluation on Trained Model---\n",
    "\n",
    "# Quantitative Evaluation: Perplexity\n",
    "print(\"\\n--- Quantitative Evaluation (Perplexity) ---\")\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity on eval set: {torch.exp(torch.tensor(eval_results['eval_loss'])):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23060708-9499-478a-bf8e-7f8a7e3ea4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
